{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D7hJlilKM485"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoOliveira6/2023.Q3-PLN/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 20/10 (sexta-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: 5`\n",
        "\n",
        "`Segundo capítulo:`21\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import base64\n",
        "\n",
        "def is_foreign_word(word, portuguese_words):\n",
        "    return word.lower() not in portuguese_words\n",
        "\n",
        "def check_title_errors(title_text):\n",
        "    words = title_text.split()\n",
        "    if len(words) > 0:\n",
        "        # Ignorar a primeira palavra se for um número ou caractere especial\n",
        "        if not words[0][0].isalpha():\n",
        "            words = words[1:]\n",
        "    for i in range(1, len(words)):  # Começa em 1 para ignorar a primeira palavra\n",
        "        if words[i][0].isupper() and not words[i-1][0].isupper():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def analyze_text(text, inconsistent_words, inappropriate_words):\n",
        "    # Verificar se uma palavra com letra maiúscula está sendo escrita de forma inconsistente\n",
        "    # Desconsiderar palavras que estão no início de parágrafos ou após pontuação final\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    for sentence in sentences:\n",
        "        words = re.findall(r'\\b\\w+\\b', sentence)  # Extrair as palavras da sentença\n",
        "        for i in range(1, len(words)):  # Começa em 1 para ignorar a primeira palavra\n",
        "            if words[i][0].isupper() and not words[i-1][0].isupper():\n",
        "                word = words[i].lower()\n",
        "                if word not in inconsistent_words:\n",
        "                    inconsistent_words[word] = []\n",
        "                inconsistent_words[word].append(i)\n",
        "            # Verificar se a palavra está na lista de palavras inadequadas\n",
        "            if words[i].lower() in inappropriate_words:\n",
        "                print(f\"Palavra inadequada encontrada: {words[i]}\")\n",
        "    return inconsistent_words\n",
        "\n",
        "#Dicionario palavras em portugues\n",
        "master = \"https://raw.githubusercontent.com/pythonprobr/palavras/master/palavras.txt\"\n",
        "req = requests.get(master)\n",
        "if req.status_code == 200:\n",
        "    print('Sucesso na URL do dicionário em portugues\\n')\n",
        "else:\n",
        "    print(\"Erro na URL do dicionário em portugues\\n\")\n",
        "req = req.text\n",
        "dicionario_palavras_portugues = set(req.split('\\n'))\n",
        "\n",
        "\n",
        "urls = ['https://brasileiraspln.com/livro-pln/1a-edicao/parte3/cap5/cap5.html', 'https://brasileiraspln.com/livro-pln/1a-edicao/parte9/cap21/cap21.html']\n",
        "\n",
        "for url in urls:\n",
        "\n",
        "    palavras_estrangeiras = []\n",
        "\n",
        "    # Lista de palavras inadequadas\n",
        "    inappropriate_words = [\"porra\", \"caralho\", \"merda\", \"puta\",]\n",
        "\n",
        "    # Fazer uma solicitação HTTP para obter o conteúdo da página\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verificar se a solicitação foi bem-sucedida\n",
        "    if response.status_code == 200:\n",
        "        # Extrair o conteúdo HTML da página\n",
        "        html = response.text\n",
        "\n",
        "        # Criar um objeto BeautifulSoup para analisar o HTML\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "        # Encontrar todos os parágrafos (geralmente estão dentro de elementos <p>)\n",
        "        all_paragraphs = soup.find_all('p')\n",
        "\n",
        "        # Encontrar todos os títulos de capítulo (geralmente estão dentro de elementos <h2>)\n",
        "        chapter_titles = soup.find_all('h2')\n",
        "\n",
        "        # Encontrar o capítulo do livro (geralmente estão dentro de elementos <h1>)\n",
        "        chapter_book = soup.find_all('h1')\n",
        "        chapter_book = chapter_book[0].get_text().strip()\n",
        "\n",
        "        # Contadores de erros\n",
        "        erros_letra_minuscula_apos_ponto = 0\n",
        "        erros_sem_espaco_apos_ponto = 0\n",
        "        erros_primeira_palavra_maiuscula = 0\n",
        "        erros_titulos_capitulo = 0\n",
        "        erros_subtitulos_capitulo = 0\n",
        "        erros_palavras_inadequadas = 0\n",
        "        erros_palavras_estrangeiras = 0\n",
        "\n",
        "        # Dicionário para armazenar palavras inconsistentes e suas posições\n",
        "        primeiras_Palavras = []\n",
        "        palavras_minusculas_apos_ponto_final = []\n",
        "        palavras_apos_ponto_final_sem_espaco = []\n",
        "        titulo_com_formatacao_errada = []\n",
        "        subtitulo_com_formatacao_errada = []\n",
        "\n",
        "        # Verificar cada parágrafo\n",
        "        for i, paragraph in enumerate(all_paragraphs, start=1):\n",
        "\n",
        "            # Dividir o texto do parágrafo em palavras, removendo pontuações\n",
        "            words = re.findall(r'\\b\\w+\\b', paragraph.get_text())\n",
        "\n",
        "            for word in words:\n",
        "                # Verificar se a palavra é estrangeira\n",
        "                if not any(char.isdigit() for char in word) and is_foreign_word(word, dicionario_palavras_portugues):\n",
        "                    if not paragraph.find(\"i\") or word not in paragraph.find(\"i\").get_text():\n",
        "                        palavras_estrangeiras.append(word)\n",
        "                        erros_palavras_estrangeiras += 1\n",
        "\n",
        "            # Verificar se a primeira palavra começa com letra maiúscula\n",
        "            if not re.search(r'^[A-Z]', paragraph.get_text()) and len(paragraph.get_text().split()) > 0:\n",
        "                erros_primeira_palavra_maiuscula += 1\n",
        "                words = paragraph.get_text().split()\n",
        "\n",
        "                if words:\n",
        "                    # A primeira palavra é a primeira palavra na lista 'words'\n",
        "                    first_word = words[0]\n",
        "                    primeiras_Palavras.append(first_word)\n",
        "\n",
        "            # Verificar se há ocorrências de letra minúscula após um ponto final\n",
        "            if(re.search(r'(?<=\\.\\s)([a-z])', paragraph.get_text())):\n",
        "              erros_letra_minuscula_apos_ponto += 1\n",
        "              lowercase_errors = re.findall(r'(?<=\\.\\s)([a-z])', paragraph.get_text())\n",
        "              palavras_minusculas_apos_ponto_final += lowercase_errors\n",
        "\n",
        "            # Verificar se há ocorrências de falta de espaço em branco após um ponto final\n",
        "            if(re.search(r'(?<=\\.[A-Za-z])([A-Za-z])', paragraph.get_text())):\n",
        "              erros_sem_espaco_apos_ponto += 1\n",
        "              espace_errors = re.findall(r'(?<=\\.[A-Za-z])([A-Za-z])', paragraph.get_text())\n",
        "              palavras_apos_ponto_final_sem_espaco += espace_errors\n",
        "\n",
        "\n",
        "        # Verificar títulos de capítulo\n",
        "        if check_title_errors(chapter_book):\n",
        "            erros_titulos_capitulo += 1\n",
        "            titulo_com_formatacao_errada.append(chapter_book)\n",
        "\n",
        "        # Verificar subtítulos de capítulo\n",
        "        for i, title in enumerate(chapter_titles, start=1):\n",
        "            title_text = title.get_text().strip()\n",
        "            if check_title_errors(title_text):\n",
        "                erros_subtitulos_capitulo += 1\n",
        "                subtitulo_com_formatacao_errada.append(title_text)\n",
        "\n",
        "        print(\"Todos os Erros do capítulo: \",chapter_book)\n",
        "        # Exibir o número total de erros para cada condição\n",
        "        print(f\"\\nErros de letra minúscula após ponto final: {erros_letra_minuscula_apos_ponto}\")\n",
        "        if(erros_letra_minuscula_apos_ponto > 0):\n",
        "            print(\"Palavras que sucedem pontuação final com letra minúscula: \", palavras_minusculas_apos_ponto_final)\n",
        "\n",
        "        print(f\"\\nErros de falta de espaço em branco após ponto final: {erros_sem_espaco_apos_ponto}\")\n",
        "        if(erros_sem_espaco_apos_ponto > 0):\n",
        "            print(\"Palavras que sucedem pontuação final sem espaço: \", palavras_apos_ponto_final_sem_espaco)\n",
        "\n",
        "        # Mensagens finais do erro de primeira palavra do parágrafo com letra minúscula\n",
        "        print(f\"\\nErros de primeira palavra de parágrafo com letra minúscula: {erros_primeira_palavra_maiuscula}\")\n",
        "        if(erros_primeira_palavra_maiuscula > 0):\n",
        "            print(\"Palavras que são primeira palavra com letra minúscula: \", primeiras_Palavras)\n",
        "\n",
        "\n",
        "        print(f\"\\nErros de títulos de capítulo fora da ABNT: {erros_titulos_capitulo}\")\n",
        "        if(erros_titulos_capitulo > 0):\n",
        "            print(\"Títulos que estão formatados de forma errada: \", titulo_com_formatacao_errada)\n",
        "\n",
        "        print(f\"\\nErros de subtítulos de capítulo fora da ABNT: {erros_subtitulos_capitulo}\")\n",
        "        if(erros_subtitulos_capitulo > 0):\n",
        "            print(\"Subtítulos que estão formatados de forma errada: \", subtitulo_com_formatacao_errada)\n",
        "\n",
        "        # Exibir o número total de erros de palavras inadequadas\n",
        "        print(f\"\\nErros de palavras inadequadas: {erros_palavras_inadequadas}\")\n",
        "\n",
        "        print(f\"\\nErros de palavras estrangeiras sem itálico: {erros_palavras_estrangeiras}\")\n",
        "        if(erros_palavras_estrangeiras > 0):\n",
        "            print(\"Palavras estrangeiras sem itálico: \", palavras_estrangeiras)\n",
        "\n",
        "        print(\"-------------------------------------------------------------\\n\")\n",
        "\n",
        "    else:\n",
        "        print(\"Não foi possível acessar a página da Wikipedia:\", response.status_code)\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28155044-983d-4aed-c59e-d0c7b752d326"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucesso na URL do dicionário em portugues\n",
            "\n",
            "Todos os Erros do capítulo:  5  ExpressÃµes multipalavras\n",
            "\n",
            "Erros de letra minúscula após ponto final: 0\n",
            "\n",
            "Erros de falta de espaço em branco após ponto final: 0\n",
            "\n",
            "Erros de primeira palavra de parágrafo com letra minúscula: 1\n",
            "Palavras que são primeira palavra com letra minúscula:  ['26/09/2023']\n",
            "\n",
            "Erros de títulos de capítulo fora da ABNT: 0\n",
            "\n",
            "Erros de subtítulos de capítulo fora da ABNT: 0\n",
            "\n",
            "Erros de palavras inadequadas: 0\n",
            "\n",
            "Erros de palavras estrangeiras sem itálico: 264\n",
            "Palavras estrangeiras sem itálico:  ['Renata', 'Ramisch', 'Ramisch', 'Aline', 'Villavicencio', 'capÃ', 'expressÃµes', 'multipalavras', 'sairÃ', 'ediÃ', 'indigesto', 'PLN', 'essas', 'expressÃµes', 'ficam', 'semÃ', 'ntica', 'acabam', 'ficando', 'elas', 'apresentam', 'idiossincrasias', 'especificidades', 'nÃ', 'permitem', 'determinadas', 'operaÃ', 'Ãµes', 'sintÃ', 'ticas', 'outros', 'conjuntos', 'definiÃ', 'Ãµes', 'sentido', 'expressÃµes', 'multipalavras', 'MWEs', 'fogem', 'significado', 'soma', 'imagine', 'expressÃ', 'â', 'sapoâ', 'fosse', 'intenÃ', 'capÃ', 'quais', 'fundamentais', 'pelas', 'guas', 'turbulentas', 'MWEs', 'esses', 'comeÃ', 'aremos', 'discussÃ', 'compÃµem', 'MWE', 'seriam', 'Seriam', 'lexemas', 'sequÃªncia', 'abordaremos', 'MWEs', 'inÃºmeras', 'essas', 'expressÃµes', 'definiÃ', 'Ãµes', 'tÃ', 'variadas', 'interessam', 'PLN', 'escolhemos', 'definiÃ', 'utilizada', 'PARSEME', 'tambÃ', 'brevemente', 'capÃ', 'estÃ', 'ExpressÃµes', 'multipalavras', 'entendidas', 'como', 'sequÃªncias', 'contÃ', 'descontÃ', 'contÃªm', 'componentes', 'lexicalizadas', 'seja', 'realizadas', 'mesmos', 'lexemas', 'incluindo', 'outra', 'sintaticamente', 'relacionada', 'ii', 'exibem', 'sintÃ', 'tica', 'semÃ', 'ntica', 'Considerando', 'essa', 'definiÃ', 'MWE', 'alguns', 'aspectos', 'importantes', 'como', 'idiossincrasias', 'coesÃ', 'sintÃ', 'tica', 'lexicalizados', 'tambÃ', 'buscamos', 'MWE', 'saiba', 'tambÃ', 'nÃ', 'EntÃ', 'explicaremos', 'abordagem', 'compostos', 'colocaÃ', 'Ãµes', 'metÃ', 'foras', 'nÃ', 'expressÃµes', 'multipalavras', 'esta', 'seja', 'apresentaremos', 'capÃ', 'tentativa', 'classificaÃ', 'MWEs', 'expressÃµes', 'nÃºcleo', 'foi', 'diretrizes', 'anotaÃ', 'PARSEME', 'utilizamos', 'definiÃ', 'Ãµes', 'refere', 'categorias', 'consideramos', 'rie', 'aspectos', 'prÃ', 'proposta', 'categorizaÃ', 'levando', 'sua', 'funÃ', 'sentenÃ', 'Traremos', 'algumas', 'discussÃµes', 'variabilidade', 'conceituaÃ', 'Ãµes', 'citaremos', 'PLN', 'envolvem', 'MWEs', 'como', 'mÃ', 'algoritmos', 'buscam', 'Essas', 'dividem', 'descoberta', 'detecÃ', 'identificaÃ', 'MWEs', 'VocÃª', 'verÃ', 'capÃ', 'apresentaÃ', 'existentes', 'portuguÃªs', 'como', 'conhecimento', 'necessÃ', 'alguma', 'questÃ', 'MWEs', 'trataremos', 'mÃ', 'avaliaÃ', 'como', 'mÃ', 'tricas', 'comumente', 'utilizados', 'comunidade', 'mÃ', 'algoritmos', 'direcionados', 'antes', 'mencionadas', 'consideramos', 'importante', 'foi', 'atÃ', 'estamos', 'MWEs', 'cientÃ', 'ficos', 'direÃ', 'resoluÃ', 'dessa', 'complexa', 'estamos', 'posiÃ', 'portuguÃªs', 'pesquisas', 'comunidade', 'internacional', 'Quais', 'desafios', 'permanecem', 'aos', 'entusiastas', 'MWEs', 'descascar', 'ngua', 'tÃ', 'nÃ', 'cabem', 'capÃ', 'estÃ', 'tentarÃ', 'construÃ', 'conhecimento', 'linguÃ', 'stico', 'PLN', 'portuguÃªs', 'Como', 'vocÃª', 'pÃ', 'capÃ', 'contÃ', 'rie', 'expressÃµes', 'multipalavras', 'fenÃ', 'linguÃ', 'sticos', 'leitoras', 'pelas', 'cenas', 'capÃ']\n",
            "-------------------------------------------------------------\n",
            "\n",
            "Todos os Erros do capítulo:  21  PLN na SaÃºde\n",
            "\n",
            "Erros de letra minúscula após ponto final: 0\n",
            "\n",
            "Erros de falta de espaço em branco após ponto final: 2\n",
            "Palavras que sucedem pontuação final sem espaço:  ['o', 'r', 'u', 'u']\n",
            "\n",
            "Erros de primeira palavra de parágrafo com letra minúscula: 2\n",
            "Palavras que são primeira palavra com letra minúscula:  ['26/09/2023', 'Ã\\x89']\n",
            "\n",
            "Erros de títulos de capítulo fora da ABNT: 1\n",
            "Títulos que estão formatados de forma errada:  ['21\\xa0 PLN na SaÃºde']\n",
            "\n",
            "Erros de subtítulos de capítulo fora da ABNT: 1\n",
            "Subtítulos que estão formatados de forma errada:  ['21.3 AplicaÃ§Ãµes de PLN na SaÃºde']\n",
            "\n",
            "Erros de palavras inadequadas: 0\n",
            "\n",
            "Erros de palavras estrangeiras sem itálico: 1306\n",
            "Palavras estrangeiras sem itálico:  ['Adriana', 'Pagano', 'Claudia', 'Moro', 'Elisa', 'Terumi', 'Rubel', 'Schneider', 'Lilian', 'Mie', 'Mukai', 'Cintho', 'Yohan', 'Gumiel', 'rea', 'saÃºde', 'importantes', 'Ãºltimos', 'beneficiado', 'uso', 'gestÃ', 'pacientes', 'aplicaÃ', 'PLN', 'sido', 'avanÃ', 'nessa', 'rea', 'permite', 'nÃ', 'estruturados', 'gerados', 'ambientes', 'nicos', 'Turchioe', 'et', 'al', 'domÃ', 'nio', 'medicina', 'abrange', 'diversos', 'utilizados', 'distintas', 'significado', 'desenvolvemos', 'convÃ', 'vio', 'Chamamos', 'essas', 'baseados', 'pesquisas', 'modelam', 'essas', 'Matthiessen', 'Matthiessen', 'Teruya', 'Wu', 'mostra', 'representativos', 'cada', 'deles', 'domÃ', 'nio', 'medicina', 'Essas', 'desenvolvidas', 'funÃ', 'Ãµes', 'especÃ', 'ficas', 'quais', 'execuÃ', 'procedimentos', 'cirÃºrgicos', 'aÃ', 'Ãµes', 'podem', 'verbalizadas', 'nÃ', 'humanas', 'Temos', 'desde', 'envolvem', 'uso', 'especializado', 'produÃ', 'conhecimento', 'tratados', 'medicina', 'didÃ', 'artigos', 'acadÃªmicos', 'atÃ', 'envolvem', 'uso', 'especializado', 'como', 'compartilhamento', 'experiÃªncias', 'mbito', 'interaÃ', 'Ãµes', 'pacientes', 'familiares', 'participantes', 'cuidados', 'saÃºde', 'comportamento', 'temos', 'como', 'bulas', 'medicamentos', 'cartilhas', 'normativas', 'manuais', 'instruÃ', 'equipamentos', 'domÃ', 'nio', 'medicina', 'tambÃ', 'quais', 'construÃ', 'realidade', 'como', 'series', 'recriam', 'interaÃ', 'Ãµes', 'contextos', 'mÃ', 'dicos', 'relevante', 'domÃ', 'nio', 'medicina', 'experiÃªncias', 'questionÃ', 'aplicados', 'nicos', 'saÃºde', 'quais', 'documentadas', 'percepÃ', 'Ãµes', 'saÃºde', 'Esses', 'conhecidos', 'PLN', 'como', 'narrativas', 'abrangem', 'evoluÃ', 'sumÃ', 'boletins', 'mÃ', 'dicos', 'prontuÃ', 'eletrÃ', 'nico', 'Cada', 'desses', 'informaÃ', 'Ãµes', 'valiosas', 'serem', 'obtidas', 'PLN', 'adequado', 'caracterÃ', 'sticas', 'Artigos', 'acadÃªmicos', 'podem', 'usados', 'extraÃ', 'ontologias', 'semÃ', 'nticas', 'permitem', 'representaÃ', 'suas', 'propriedades', 'relaÃ', 'Ãµes', 'Essas', 'ontologias', 'podem', 'usadas', 'compreensÃ', 'tÃ', 'cnicos', 'diferentes', 'reas', 'saÃºde', 'permitindo', 'informaÃ', 'Ãµes', 'sejam', 'compartilhadas', 'precisa', 'Jiang', 'et', 'al', 'TambÃ', 'podemos', 'padrÃµes', 'construÃ', 'preditivos', 'Lee', 'et', 'al', 'Narrativas', 'nÃ', 'estruturados', 'oferecem', 'informaÃ', 'Ãµes', 'valiosas', 'incluindo', 'mÃ', 'outras', 'informaÃ', 'Ãµes', 'relevantes', 'mineraÃ', 'desses', 'usada', 'padrÃµes', 'permitindo', 'compreensÃ', 'condiÃ', 'construÃ', 'preditivos', 'possÃ', 'veis', 'complicaÃ', 'Ãµes', 'doenÃ', 'Wu', 'et', 'al', 'EletrÃ', 'nico', 'SaÃºde', 'RES', 'como', 'denominado', 'inglÃªs', 'Electronic', 'Health', 'Record', 'EHR', 'quantidade', 'gerados', 'atenÃ', 'aos', 'pacientes', 'aumentou', 'significativamente', 'prontuÃ', 'eletrÃ', 'nicos', 'podem', 'estruturados', 'semiestruturados', 'nÃ', 'estruturados', 'eles', 'oferecendo', 'quantidade', 'informaÃ', 'Ãµes', 'mineraÃ', 'desses', 'tendÃªncias', 'padrÃµes', 'relaÃ', 'tratamentos', 'resultados', 'permitindo', 'gestÃ', 'cuidado', 'planejamento', 'assistÃªncia', 'Shickel', 'et', 'al', 'nicos', 'presentes', 'narrativas', 'nÃ', 'estruturados', 'apresentam', 'caracterÃ', 'sticas', 'Ãºnicas', 'dificultam', 'sua', 'interpretaÃ', 'Esses', 'apresentados', 'mÃ', 'especializada', 'repleta', 'tÃ', 'cnicos', 'jargÃµes', 'abreviaturas', 'podem', 'distintos', 'saÃºde', 'Esses', 'tambÃ', 'podem', 'digitaÃ', 'gramÃ', 'tica', 'tornando', 'interpretaÃ', 'complexa', 'Dalianis', 'apresenta', 'narrativa', 'nica', 'adaptada', 'ilustraÃ', 'Nela', 'podemos', 'informaÃ', 'Ãµes', 'podem', 'estruturadas', 'categorias', 'destacadas', 'rotuladas', 'chamamos', 'narrativas', 'diferentes', 'quais', 'apresentam', 'desafios', 'especÃ', 'ficos', 'tambÃ', 'relevÃ', 'ncia', 'informaÃ', 'Ãµes', 'registradas', 'evoluÃ', 'podem', 'descritivas', 'detalhadas', 'outros', 'sumÃ', 'podem', 'informaÃ', 'Ãµes', 'importantes', 'condiÃ', 'podem', 'informais', 'fragmentadas', 'dificulta', 'sua', 'treinados', 'outros', 'outros', 'domÃ', 'nios', 'demanda', 'anotaÃ', 'narrativas', 'contarmos', 'refinados', 'Como', 'anotaÃ', 'narrativas', 'requer', 'dificulta', 'construÃ', 'datasets', 'treinamento', 'PLN', 'Como', 'resultado', 'aplicaÃ', 'tÃ', 'cnicas', 'mÃ', 'nicos', 'sofre', 'limitaÃ', 'Ãµes', 'disponibilidade', 'anotados', 'manualmente', 'Koleck', 'et', 'al', 'saÃ', 'genÃ', 'prÃ', 'sendo', 'saÃ', 'avaliada', 'manualmente', 'anotaÃ', 'Depclin', 'Br', 'sendo', 'desenvolvida', 'computaÃ', 'PUCPR', 'linguistas', 'UFMG', 'Trata', 'narrativas', 'anotadas', 'entidades', 'domÃ', 'nio', 'nico', 'constituindo', 'SemClinBr', 'et', 'al', 'foi', 'anotada', 'morfossintaticamente', 'genÃ', 'portuguÃªs', 'anotaÃ', 'revisada', 'manualmente', 'et', 'al', 'Essa', 'foi', 'utilizada', 'refinamento', 'genÃ', 'anotaÃ', 'automÃ', 'tica', 'concluÃ', 'anotaÃ', 'DepClinBr', 'anotado', 'relaÃ', 'Ãµes', 'dependÃªncia', 'podem', 'minerados', 'utilizados', 'entidades', 'nomeadas', 'anotadas', 'SemClinBr', 'ilustra', 'correlaÃ', 'anotaÃ', 'Ãµes', 'morfossintÃ', 'ticas', 'entidades', 'construÃ', 'narrativas', 'nÃ', 'estruturados', 'estÃ', 'sujeita', 'restriÃ', 'Ãµes', 'tÃ', 'cnicas', 'dizem', 'respeito', 'Essa', 'limita', 'capacidade', 'construÃ', 'datasets', 'treinamento', 'PLN', 'Chen', 'Chen', 'Como', 'foi', 'apontado', 'essa', 'limitaÃ', 'utilizados', 'genÃ', 'ngua', 'quais', 'precisam', 'refinados', 'especÃ', 'ficos', 'domÃ', 'nio', 'fine', 'tuning', 'sua', 'precisÃ', 'relevÃ', 'ncia', 'Lee', 'et', 'al', 'veremos', 'alguns', 'aplicaÃ', 'Ãµes', 'PLN', 'nicos', 'PLN', 'rea', 'mÃ', 'prediÃ', 'aplicada', 'diversas', 'demandas', 'cuidado', 'saÃºde', 'como', 'evoluÃ', 'mÃ', 'detecÃ', 'detecÃ', 'depressÃ', 'outras', 'Essas', 'demandas', 'envolvem', 'classificaÃ', 'nicos', 'como', 'narrativas', 'pacientes', 'prontuÃ', 'eletrÃ', 'nicos', 'mÃ', 'dicos', 'outros', 'saÃºde', 'mÃ', 'dicos', 'outros', 'saÃºde', 'decisÃµes', 'precisas', 'prediÃ', 'doenÃ', 'estÃ', 'gios', 'iniciais', 'permitindo', 'tratamentos', 'eficazes', 'prevenindo', 'complicaÃ', 'Ãµes', 'prediÃ', 'cada', 'maximizando', 'sua', 'eficÃ', 'minimizando', 'efeitos', 'colaterais', 'detecÃ', 'depressÃ', 'acidentes', 'qualidade', 'pacientes', 'prediÃ', 'aplicaÃ', 'sucedida', 'PLN', 'rea', 'saÃºde', 'Yan', 'Gustad', 'NytrÃ', 'Alguns', 'envolvendo', 'prediÃ', 'classificaÃ', 'nicos', 'portuguÃªs', 'GonÃ', 'et', 'al', 'Ulbrich', 'et', 'al', 'et', 'al', 'aplicaÃ', 'PLN', 'rea', 'mÃ', 'desidentificaÃ', 'pacientes', 'anonimizaÃ', 'pseudonimizaÃ', 'Esta', 'envolve', 'remoÃ', 'informaÃ', 'Ãµes', 'possam', 'como', 'endereÃ', 'nÃºmero', 'outras', 'informaÃ', 'Ãµes', 'pessoais', 'anonimizaÃ', 'necessÃ', 'ria', 'pacientes', 'regulamentaÃ', 'Ãµes', 'proteÃ', 'como', 'ProteÃ', 'LGPD', 'Protection', 'Regulation', 'GDPR', 'UniÃ', 'anonimizaÃ', 'nicos', 'desafiador', 'esses', 'contÃªm', 'informaÃ', 'Ãµes', 'altamente', 'sensÃ', 'veis', 'complexas', 'como', 'mÃ', 'tratamentos', 'outros', 'detalhes', 'podem', 'necessÃ', 'tÃ', 'cnicas', 'avanÃ', 'adas', 'PLN', 'como', 'uso', 'remover', 'informaÃ', 'Ãµes', 'sensÃ', 'veis', 'pacientes', 'Jones', 'et', 'al', 'Existem', 'diversas', 'tÃ', 'cnicas', 'podem', 'utilizadas', 'desidentificaÃ', 'nicos', 'dependendo', 'informaÃ', 'removida', 'nÃ', 'vel', 'anonimizaÃ', 'desejado', 'AlÃ', 'dessas', 'tÃ', 'cnicas', 'tambÃ', 'possÃ', 'vel', 'mÃ', 'avanÃ', 'ados', 'PLN', 'como', 'detecÃ', 'remoÃ', 'mÃ', 'dicos', 'especÃ', 'ficos', 'uso', 'tÃ', 'cnicas', 'identificaÃ', 'baseadas', 'tentam', 'semÃ', 'ntica', 'remoÃ', 'substituiÃ', 'informaÃ', 'Ãµes', 'pessoais', 'desidentificaÃ', 'pacientes', 'permite', 'nicos', 'sejam', 'utilizados', 'pesquisa', 'pacientes', 'avanÃ', 'medicina', 'permitindo', 'descoberta', 'padrÃµes', 'tendÃªncias', 'doenÃ', 'tratamentos', 'outros', 'aspectos', 'saÃºde', 'Liu', 'et', 'al', 'et', 'al', 'temos', 'portuguÃªs', 'nessa', 'extraÃ', 'nicos', 'relevantes', 'aplicaÃ', 'PLN', 'rea', 'mÃ', 'Essa', 'envolve', 'identificaÃ', 'entidades', 'relevantes', 'nicos', 'como', 'tratamentos', 'medicamentos', 'outros', 'especÃ', 'ficos', 'rea', 'saÃºde', 'Essa', 'identificaÃ', 'geralmente', 'tÃ', 'cnicas', 'NER', 'inglÃªs', 'Named', 'Entity', 'Recognition', 'permitem', 'identificaÃ', 'classificaÃ', 'automÃ', 'tica', 'entidades', 'nÃ', 'estruturados', 'ilustra', 'entidades', 'reconhecidas', 'narrativa', 'nica', 'elaborada', 'ilustraÃ', 'AlÃ', 'identificaÃ', 'entidades', 'outras', 'tÃ', 'cnicas', 'PLN', 'tambÃ', 'podem', 'utilizadas', 'extraÃ', 'nicos', 'relevantes', 'como', 'detecÃ', 'negaÃ', 'resoluÃ', 'ambiguidades', 'detecÃ', 'negaÃ', 'Ãºtil', 'negado', 'mÃ', 'alguma', 'condiÃ', 'precisÃ', 'deteÃ', 'nao', 'nagaÃ', 'interpretaÃ', 'nicos', 'Nath', 'Lee', 'Lee', 'Outra', 'tÃ', 'cnica', 'importante', 'extraÃ', 'nicos', 'mapeamento', 'consiste', 'associaÃ', 'nicos', 'padronizados', 'como', 'ClassificaÃ', 'Internacional', 'DoenÃ', 'CID', 'Systemized', 'Nomenclature', 'of', 'Medicine', 'SNOMED', 'CT', 'permite', 'organizaÃ', 'interpretaÃ', 'nicos', 'facilitando', 'decisÃ', 'mÃ', 'Fennelly', 'et', 'al', 'extraÃ', 'nicos', 'relevantes', 'nicos', 'permitindo', 'identificaÃ', 'padrÃµes', 'tendÃªncias', 'doenÃ', 'tratamentos', 'outros', 'aspectos', 'saÃºde', 'AlÃ', 'essas', 'tÃ', 'cnicas', 'PLN', 'tambÃ', 'podem', 'utilizadas', 'construÃ', 'sistemas', 'decisÃ', 'mÃ', 'auxiliam', 'saÃºde', 'tratamentos', 'adequados', 'cada', 'Demner', 'Fushman', 'Chapman', 'McDonald', 'representaÃ', 'fica', 'organiza', 'informaÃ', 'Ãµes', 'interesse', 'pesquisa', 'extraÃ', 'relaÃ', 'Ãµes', 'temporais', 'provÃ', 'caracterÃ', 'stica', 'presentes', 'EletrÃ', 'nicos', 'SaÃºde', 'Esses', 'contÃªm', 'mÃºltiplos', 'nicos', 'referentes', 'diferentes', 'momentos', 'Gumiel', 'et', 'al', 'extraÃ', 'relaÃ', 'Ãµes', 'temporais', 'concentra', 'organizaÃ', 'menÃ', 'Ãµes', 'sendo', 'essas', 'menÃ', 'Ãµes', 'eventos', 'mÃ', 'dicos', 'expressÃµes', 'temporais', 'nico', 'eventos', 'mÃ', 'dicos', 'circunstÃ', 'ncias', 'relevÃ', 'ncia', 'delimitado', 'aplicaÃ', 'extraÃ', 'informaÃ', 'Ãµes', 'significativas', 'apropriado', 'eventos', 'como', 'menÃ', 'Ãµes', 'tratamentos', 'medicamentos', 'uso', 'realizados', 'respectivos', 'resultados', 'expressÃµes', 'temporais', 'envolvem', 'menÃ', 'Ãµes', 'como', 'duraÃ', 'indicaÃ', 'Ãµes', 'realizou', 'determinada', 'notÃ', 'vel', 'expressÃµes', 'temporais', 'tÃªm', 'significado', 'eventos', 'podem', 'sentido', 'relacionados', 'essas', 'menÃ', 'Ãµes', 'empregadas', 'tÃ', 'cnicas', 'PLN', 'como', 'Reconhecimento', 'Entidades', 'Nomeadas', 'NER', 'consiste', 'automaticamente', 'eventos', 'expressÃµes', 'temporais', 'eventos', 'expressÃµes', 'temporais', 'identificados', 'aplica', 'extraÃ', 'relaÃ', 'Ãµes', 'temporais', 'tÃ', 'cnica', 'PLN', 'concentra', 'conexÃ', 'eventos', 'expressÃµes', 'temporais', 'cada', 'acaba', 'sendo', 'relacionada', 'perÃ', 'especÃ', 'relaÃ', 'Ãµes', 'temporais', 'nico', 'diversas', 'reas', 'pesquisa', 'emergem', 'DoenÃ', 'apresentam', 'temporalidade', 'extremamente', 'relevante', 'existem', 'fluxos', 'contÃ', 'nuos', 'extensos', 'quais', 'podem', 'extraÃ', 'padrÃµes', 'significativos', 'Sheikhalishahi', 'et', 'al', 'progressÃ', 'doenÃ', 'eventos', 'registrados', 'cronologicamente', 'eventos', 'relevantes', 'apenas', 'momentos', 'especÃ', 'ficos', 'como', 'problemas', 'mÃ', 'dicos', 'identificados', 'consulta', 'relatados', 'Sheikhalishahi', 'et', 'al', 'ineficaz', 'hipertensÃ', 'monoterapia', 'terapias', 'medicamentos', 'combinados', 'algumas', 'informaÃ', 'Ãµes', 'progressÃ', 'doenÃ', 'podem', 'discernidas', 'extraÃ', 'relaÃ', 'Ãµes', 'temporais', 'Gumiel', 'et', 'al', 'aplicaÃ', 'prÃ', 'tica', 'rea', 'saÃºde', 'utilizada', 'evoluÃ', 'nico', 'possÃ', 'veis', 'tendÃªncias', 'previsÃµes', 'AlÃ', 'integrada', 'sistemas', 'decisÃ', 'mÃ', 'contribuindo', 'seleÃ', 'tratamentos', 'adequados', 'cada', 'sumarizaÃ', 'evoluÃ', 'Ãµes', 'PLN', 'como', 'informaÃ', 'Ãµes', 'relevantes', 'nicos', 'versÃ', 'resumida', 'legÃ', 'vel', 'dessas', 'informaÃ', 'Ãµes', 'exibe', 'fictÃ', 'narrativa', 'nica', 'sumarizada', 'sumarizaÃ', 'evoluÃ', 'Ãµes', 'utilizadas', 'tÃ', 'cnicas', 'sumarizaÃ', 'automÃ', 'tica', 'podem', 'baseadas', 'abordagens', 'extrativas', 'abstrativas', 'abordagem', 'extrativa', 'importantes', 'selecionadas', 'combinadas', 'abordagem', 'abstrativa', 'gerado', 'ntese', 'informaÃ', 'Ãµes', 'gerando', 'versÃ', 'nÃ', 'necessariamente', 'contÃ', 'mesmas', 'sumarizaÃ', 'evoluÃ', 'Ãµes', 'utilizadas', 'tÃ', 'cnicas', 'incluindo', 'NER', 'entidades', 'relevantes', 'PoS', 'of', 'Speech', 'gramÃ', 'tica', 'tambÃ', 'tÃ', 'cnicas', 'sintÃ', 'tica', 'semÃ', 'ntica', 'Essa', 'PLN', 'Ãºtil', 'rea', 'saÃºde', 'permite', 'eles', 'analisem', 'brevemente', 'informaÃ', 'Ãµes', 'importantes', 'pacientes', 'como', 'doenÃ', 'realizados', 'tratamentos', 'prescritos', 'outras', 'informaÃ', 'Ãµes', 'Gulden', 'et', 'al', 'PLN', 'rea', 'nica', 'tenha', 'avanÃ', 'ado', 'significativamente', 'Ãºltimos', 'existem', 'desafios', 'serem', 'superados', 'Alguns', 'desses', 'desafios', 'incluem', 'importante', 'destacar', 'PLN', 'possa', 'Ãºtil', 'interpretaÃ', 'nicos', 'nÃ', 'experiÃªncia', 'conhecimento', 'nico', 'mÃ', 'outros', 'saÃºde', 'valiosa', 'decisÃµes', 'nÃ', 'julgamento', 'nico', 'Ressalta', 'desenvolvimento', 'tecnologias', 'PLN', 'rea', 'nica', 'seja', 'como', 'cuidado', 'nÃ', 'como', 'substituiÃ', 'aos', 'saÃºde', 'Sistema', 'nico', 'SaÃºde', 'informaÃ', 'Ãµes', 'usuÃ', 'coletadas', 'armazenadas', 'ProntuÃ', 'EletrÃ', 'nico', 'PEC', 'prÃ', 'determinados', 'podem', 'preenchidos', 'â', 'ï', 'ProteÃ', 'Pessoais', 'LGPD', 'nÂº', 'DisponÃ', 'vel', 'www', 'gov', 'br', 'â', 'pt', 'br', 'â', 'acesso', 'informacao', 'â', 'lgpdâ', 'ï', 'protection', 'the', 'DisponÃ', 'vel', 'commission', 'law', 'law', 'topic', 'protection', 'protection', 'eu_enâ', 'ï']\n",
            "-------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}